多线程: 线程概念、线程控制、线程安全、线程池
1、线程概念
在传统操作系统上pcb是一个进程，描述一个程序的运行，还有一个tcb描述实现线程
但是在Linux下使用pcb描述实现了程序调度，并且这些pcb共用同一个虚拟地址空间
相较于传统的pcb更加轻量化一点，因此也把Linux下的pcb称之为轻量级进程
进程是系统资源分配的基本单位，线程是CPU调度的基本单位
线程间的独有与共享:
独有: 栈、寄存器、信号屏蔽字、errno、标识符
共享: 虚拟地址空间（代码段、数据段）、文件描述符表、信号处理方式、工作路径、用户ID、组ID
多线程/多进程进行多任务处理：
多线程:
	1）线程间通信更加方便灵活（全局变量、函数传参）
	2）线程的创建/销毁成本更低
	3）线程间的调度成本更低
	4）异常和某些系统调用针对的是整个进程
多进程:
	具有独立性，因此更加的稳定、健壮   --shell/服务器
例如: 对主功能程序安全稳定性要求更高的最好使用多进程，剩下的多线程
共同优点:
	在CPU资源足够的情况下，可以使程序的性能更高（并非线程越多越好，调度的时间成本）
	例：CPU密集型程序/IO密集型程序  并行压缩CPU处理/IO等待时间
2、线程控制
线程创建、线程终止、线程等待、线程分离
线程控制的接口都是库函数，操作系统并没有向用户提供一个轻量级进程的接口，因此大佬们才封装了一套线程控制接口
使用时需要链接库文件 -lpthread/-pthread
线程创建:
	int pthread_create(pthread_t *tid, pthread_attr_t *attr, void* (*thread_routine)(void *arg), void *arg);
	tid 用于获取线程id，通过这个id可以找到线程的描述信息，进而访问pcb（轻量级进程完成控制）
	attr 线程属性，通常置NULL
	thread_routine 线程入口函数，创建一个线程就是为了运行这个函数，函数运行完毕，则线程退出
	arg 通过线程入口函数，传递给线程的参数
	返回值: 0<->成功 非0值<->失败返回(errno)
ps -L： 功能是查看轻量级进程信息 ps -efL
	pcb-> 	pid 轻量级进程ID <-> LWP（light weight process）
	pcb-> 	tgid 线程组ID <-> 进程id，也就是外边命令所看到的进程id；而这个id值等于主线程的pcb->pid
		tid 线程在虚拟地址空间中开辟的线程空间的首地址
线程终止:
	1）普通线程入口函数中的return（main函数中的return退出的是进程）
	2）void pthread_exit(void *retval); // 退出一个线程，谁调用，谁退出，retval--线程返回值
	3）int pthread_cancel(pthread_t tid); // 退出指定的线程；tid就是指定的线程id
	注意:
	1、线程退出，也不会完全释放资源，需要被其它进程等待
	2、取消自己是一种违规操作，不是主流做法（了解）
	3、主线程退出，其它线程正常退出，也不是主流做法（了解）
	4、主线程退出，并不影响整个进程的运行，只有所有的线程退出，进程才退出
线程等待:
	等待一个线程的退出，获取退出线程的返回值，回收这个线程所占用的资源
	int pthread_join(pthread_t tid, void **retval);
	tid 指定要等待的线程id
	retval 用于获取线程退出返回值  <->  pthread_exit(void *retval)
	不是所有的线程都能被等待，一个线程被创建，默认情况下有一个属性--joinable；
	处于joinable属性的线程退出后，不会自动释放资源，需要被等待
线程分离：
	将线程的属性从joinable设置为detach；处于detach属性的线程退出后会自动释放资源，不需要被等待
	int pthread_detach(pthread_t tid); // 分离指定的线程
	等待一个被分离的线程，则pthread_join会返回错误：这不是一个joinable线程
	因为在获取返回值的时候将获取不到，detach属性的线程退出后已经自动的释放了资源
	1）线程的分离可以在任意地方，可以在线程入口函数中让线程分离自己，也可以在创建线程后分离，如何选择取决于个人习惯
3、线程安全
在多个执行流中对同一个临界资源进行操作访问，而不会造成数据二义
如何实现线程安全：同步与互斥
	互斥：通过保证同一时间只有一个执行流可以对临界资源进行访问（一个执行流访问期间，其它执行流不能访问），来保证数据访问的安全性
	同步：通过一些条件判断来实现多个执行流对临界资源访问的合理性（有资源则访问，没有资源则等着，等有资源了再被唤醒）
如何实现互斥：互斥锁
如何实现同步：条件变量 --posix标准的信号量
互斥锁：定义一个互斥锁用来标记当前临界资源的访问状态
	有一个技术器：0/1   0-不可访问  1-可以访问	计数器初值为1。
	每一个线程访问临界资源之前，先判断计数，当前临界资源的状态（是否有人正在访问--正在访问的线程将状态置位为0）
	1）第一个线程访问的时候，判断可以访问，因此将状态置位为不可访问，然后去访问资源
	2）其它线程访问的时候，发现不可访问，就陷入等待（等待：将pcb状态置为可中断休眠态，则不可被操作系统调度）
	3）第一个线程访问临界资源完毕后，将状态置位为可以访问，唤醒等待的线程，大家重新开始竞争这个资源（唤醒：将pcb状态置为运行态，则可以开始调度）
	伪代码：
		xchgb	%al count
		if (寄存器的值>0) {
			return ;
		}
	pthread_mutex_t = PTHREAD_MUTEX_INITIALIZER; 互斥锁变量类型
	pthread_mutex_init(pthread_mutex_t *mutex, pthread_mutexattr_t *attr); // 初始化互斥锁
	pthread_mutex_lock(pthread_mutex_t *mutex); // 在临界资源访问之前加锁
	pthread_mutex_unlock(pthread_mutex_t *mutex); // 在临界资源访问完毕后解锁
	pthread_mutex_destory(pthread_mutex_t *mutex); // 销毁互斥锁
	pthread_mutex_trylock(...) / pthread_mutex_timedlock(...)
同步的实现：保证资源访问的合理性
	有资源的时候可以获取，没有资源的时候则需要让线程等待，等待被唤醒（其它线程产生一个资源的时候）
条件变量：向用户提供了两个接口，使一个线程等待的接口和唤醒一个线程的接口 + 等待队列
	条件变量只是提供了等待与唤醒的功能，但是什么时候等待，什么时候唤醒，需要用户自己来做判断
操作接口：
	pthread_cond_t cond = PTHREAD_COND_INITIALIZER;
	int pthread_cond_init(pthread_cond_t *cond, pthread_condattr_t *attr);	
	int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex); // 使当前调用执行流陷入阻塞等待
	int pthread_cond_signal(pthread_cond_t *cond); // 唤醒至少一个条件变量等待队列中的执行流
	int pthread_cond_broadcast(pthread_cond_t *cond); // 广播唤醒所有等待的执行流
	int pthread_cond_destroy(pthread_cond_t *cond);
条件变量这里的条件判断应该是一个循环判断：
	因为pthread_cond_signal是至少唤醒一个等待的执行流，假设多个吃面执行流被唤醒之后，都尝试去加锁，
	但是只有一个能加锁成功，然后去吃面，吃完面后解锁，但是解锁之后有可能获取到锁的执行流还是一个吃面执行流，
	这时候就有可能在没有面的情况下又吃了一碗（逻辑混乱），因此条件判断必须是一个循环判断，被唤醒加锁成功后，
	应该再次判断条件是否能够操作
不同角色的执行流，应该等待在不同的条件变量队列中：
	因为如果多个角色的执行流都等待在同一个等待队列中，有可能某个吃面执行流吃完面之后，
	从等待队列中唤醒的不是做面执行流而又是一个吃面执行流，但是这个吃面执行流因为没有面而陷入等待，
	唤醒的不是厨师，因此没有人做面，美食家也吃不到面，因此都陷入阻塞
让不同的角色加入不同的等待队列中：
	这时候就可以清晰的实现，美食家吃完美食后，去厨师队列唤醒厨师，而厨师做好美食后去美食家队列唤醒美食家
	pthread_cond_wait：集合了三步操作：解锁->休眠 ->被唤醒后加锁；解锁和休眠是原子操作
	pthread_cond_signal：唤醒至少一个执行流（因此才需要循环判断条件）

生产者与消费者模型：
	1、解耦合，生产者模块与消费者模块并不直接交互，都是仅操作线程安全的队列
	2、支持忙闲不均，队列中有多个节点可以起缓冲作用
	3、支持并发
生产者与消费者模型的实现：一个场所，两种角色，三种关系
	生产者与生产者应该具备互斥关系
	消费者与消费者应该具备互斥关系
	生产者与消费者应该具备同步+互斥关系
实现一个线程安全的队列+多个角色的执行流
	封装一个阻塞队列类
	class BlockQueue
	{
	private:
		std::queue<int> _queue;
		int _capacity; // 限制队列中节点的最大数量
		pthread_mutex_t _mutex; // 实现互斥
		pthread_cond_t _cond_pro; // 生产者队列
		pthread_cond_t _cond_con; // 消费者队列
	public:
		BlockQueue(int qmax){//初始化资源}
		~BlockQueue(){//释放资源}
		bool Push(int &data); // 入队
		bool Pop(int *data); // 出队
	};
信号量：POSIX---主要用于实现线程/进程间的同步
	本质：计数器+等待队列+向外提供的使执行流阻塞/唤醒的功能接口
	计数器：对资源进行计数，统计当前的资源数量，通过自身的计数，就可以进行条件判断，是否能够进行操作，若不能获取资源，则阻塞当前执行流
	在程序初始化阶段，根据实际资源数量初始化信号量计数器数值，在每次获取资源之前，先获取信号量（先判断计数器是否大于0，若大于0则计数-1，
	直接返回获取数据，否则阻塞当前执行流）；当它执行流生产一个资源后，先判断计数器是否<0，若小于0，则唤醒一个执行流，然后进行计数+1
操作接口：
	sem_t sem;
	int sem_init(sem_t *sem, int pshared, int value); // 初始化操作
	pshared：这个参数决定了当前的信号量用于进程间还是线程间；0--线程间 !0--进程间
	value：实际的资源数量，用于初始化信号量计数器初值
	int sem_wait(sem_t *sem); // 阻塞操作--若没有资源则直接阻塞
	int sem_post(sem_t *sem); // 唤醒操作
	int sem_destroy(sem_t *sem); // 销毁操作
信号量实现互斥：
	保证资源计数不大于1，就可以完成
	sem_init(&sem, 0, 1);
	sem_wait(&sem);
	...
	sem_post(&sem);
使用信号量实现生产者与消费者模型：
	封装一个线程安全的环形队列：
	class RingQueue
	{
	private:
		std::vector<int> _array; // 数组
		int _capacity; // 数组的节点数量
		int _pos_write; // 写指针当前位置，写入数据后，写指针向后移动
		int _pos_read; // 读指针当前位置，读取数据后，读指针向后移动
		sem_t _sem_space; // 空闲空间计数器，有多少个空闲空间，就可以生产多少个数据
		sem_t _sem_data; // 数据资源计数器，有多少个数据资源，就可以获取多少个数据
		sem_t _sem_lock; // 实现安全的锁
	public:
		RingQueue(int qmax){//初始化资源}
		RingQueue(){//释放资源}
		bool Push(int &data); // 入队
		bool Pop(int *data); // 出队
	};

死锁：多个执行流在对多个资源进行争抢操作，但是因为推进顺序不当，而导致互相等待，流程无法继续推进
死锁产生的四个必要条件：
	1、互斥条件：一个锁只有一个人能加，我加了锁，别人就不能加了
	2、不可剥夺条件：我加的锁，别人不能替我释放
	3、请求与保持条件：我加了A锁，然后去请求B锁，但是请求不到B锁，我也不释放A锁
	4、环路等待条件：我拿着A锁去请求B锁，对方拿着B锁请求A锁
预防死锁：破坏产生死锁的四个必要条件-锁资源按序一次性分配；加锁的时候可以使用非阻塞加锁，若无法加锁，则将手中的其他锁释放掉
避免死锁：银行家算法，死锁检测算法
银行家算法：
	定义两种状态：安全/非安全 - 现在有多少钱，现在哪些人已经借了钱，当前还有哪些人需要借多少钱；
	现在都有哪些钱，当前哪些执行流已经获取了哪些锁，当前哪些执行流想要哪些锁；
	若给一个执行流分配指定的锁有可能会造成环路等待（非安全状态），则不予分配，并且回溯释放当前执行流已有的资源
读者写者模型：
	少量写临界资源的执行流+大量读临界资源的执行流
	不能同时写，但是可以同时读
	写的时候别人既不能写也不能读；但是读的时候不能写
	写互斥，读共享 --- 读写锁
读写锁的实现：
	一个读者计数：>0，表示当前有人正在读，想要加写锁的人就需要等待，而想要加读锁的可以继续加
	一个写者计数：>0，表示当前有人正在写，想要加写锁或读锁的人都需要等待
	其中不能加锁时的等待，通过自旋锁实现
自旋锁：循环判断条件，并且强占CPU（一直处于运行状态，判断条件，CPU不可被剥夺）
	比较消耗CPU，比较适用于等待时间比较短的操作
	调研：自旋锁为什么要一直占用CPU，不能被切换出去？
	调研各种锁：悲观锁/乐观锁，CAS锁，无锁编程，可重入锁，不可重入锁

线程池：创建一大堆线程，以及一个线程安全的队列；
	若有任务需要处理，则将任务抛入线程池中，线程池中的线程，就会去处理这个任务；
线程池优点：
	1、避免峰值压力下，资源耗尽的风险
	2、节省线程创建/销毁带来的时间成本
使用线程池的理由：
	针对请求处理，单个线程处理效率太低，采用多线程处理
	但是每个请求都创建一个线程，有可能线程创建过多，效率没有增加反而降低/瞬间资源消耗过度，程序崩溃
	因此不能无限制的创建线程处理请求
	处理一个任务，创建一个线程时间t1，处理时间t2，销毁线程t3 t=t1+t2+t3
	因此最好能够提前将线程创建好，这些线程不断的去处理即可
封装实现一个线程池：
	一堆已经创建好的线程+线程安全的任务队列
如何让每一个线程针对不同的任务，有不同的处理方法，让线程池灵活起来
向线程池抛入数据的时候，顺便将处理函数一起抛入，线程池中的线程使用函数处理数据即可，最好这个函数由用户自己定义
封装任务类：
	typedef void (*thread_callback)(void *data);
	class ThreadTask
	{
	private:
		void *_data; // 用户要处理数据
		thread_callback _handler;
	public:
		ThreadTask(void *data, thread_callback handler);
		void Run() {_handler(_data);}
	}; // 线程池任务类
	线程池中线程获取一个任务，只需要调用成员函数Run就可以实现，使用用户传入的函数处理用户传入的数据，
	而线程池就不用关心改用什么方法处理数据了
	降低了外部耦合度：不管任务的处理有任何改变，都跟线程池没有关系，不需要修改线程池的代码
	class ThreadPool
	{
	private:
		int _max_thr;
		std::queue<ThreadTask> _queue;
		int _max_queue;
		pthread_mutex_t _mutex;
		pthread_cond_t _cond_pro;
		pthread_cond_t _cond_con;
	public:
		ThreadPool(){//完成初始化操作}
		~ThreadPool(){//销毁操作}
		bool AddTask(ThreadTask &tt); // 任务入队
		bool init(); // 创建大量的线程
	private:
		void* thr_start(void *arg); // 线程入口函数
	};
	线程入口函数：不断的获取任务，调用任务成员函数Run就可以了